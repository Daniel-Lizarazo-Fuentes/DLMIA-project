{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "shm             128G     0  128G   0% /dev/shm\n"
     ]
    }
   ],
   "source": [
    "df -h /dev/shm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kill all nnUNet related processes and children if necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:\n",
      " kill [options] <pid> [...]\n",
      "\n",
      "Options:\n",
      " <pid> [...]            send signal to every <pid> listed\n",
      " -<signal>, -s, --signal <signal>\n",
      "                        specify the <signal> to be sent\n",
      " -q, --queue <value>    integer value to be sent with the signal\n",
      " -l, --list=[<signal>]  list all signal names, or convert one to a name\n",
      " -L, --table            list all signal names in a nice table\n",
      "\n",
      " -h, --help     display this help and exit\n",
      " -V, --version  output version information and exit\n",
      "\n",
      "For more details see kill(1).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "123",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# ps aux | grep nnUNetv2_train\n",
    "ps aux | grep nnUNetv2_train | grep -v grep | awk '{print $2}' | xargs kill -9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  3 18:44:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A16                     Off |   00000000:1B:00.0 Off |                    0 |\n",
      "|  0%   56C    P0             60W /   62W |   13748MiB /  15356MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A16                     Off |   00000000:1C:00.0 Off |                    0 |\n",
      "|  0%   53C    P0             58W /   62W |    4651MiB /  15356MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A16                     Off |   00000000:1D:00.0 Off |                    0 |\n",
      "|  0%   30C    P8             16W /   62W |       6MiB /  15356MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A16                     Off |   00000000:1E:00.0 Off |                    0 |\n",
      "|  0%   28C    P8             15W /   62W |       6MiB /  15356MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA A16                     Off |   00000000:CE:00.0 Off |                    0 |\n",
      "|  0%   30C    P8             14W /   62W |       6MiB /  15356MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA A16                     Off |   00000000:CF:00.0 Off |                    0 |\n",
      "|  0%   31C    P8             14W /   62W |       6MiB /  15356MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA A16                     Off |   00000000:D0:00.0 Off |                    0 |\n",
      "|  0%   29C    P8             14W /   62W |       6MiB /  15356MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA A16                     Off |   00000000:D1:00.0 Off |                    0 |\n",
      "|  0%   27C    P8             14W /   62W |       6MiB /  15356MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "nvidia-smi\n",
    "# watch -n0.1 nvidia-smi # does not render in notebook, needs to be in native bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export nnUNet_raw=\"/home/jovyan/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/home/jovyan/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/jovyan/nnUNet_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/nnUNet_raw\n",
      "/bin/bash\n"
     ]
    }
   ],
   "source": [
    "echo $nnUNet_raw\n",
    "echo $SHELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cat /home/jovyan/.local/lib/python3.10/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\n",
    "#nano /home/jovyan/.local/lib/python3.10/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# chmod +x x.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# ./x.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    ".local/bin/nnUNetv2_plan_and_preprocess -d 300 --verify_dataset_integrity -np 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset400_supersecret\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/.local/bin/nnUNetv2_plan_and_preprocess\", line 8, in <module>\n",
      "    sys.exit(plan_and_preprocess_entry())\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_entrypoints.py\", line 180, in plan_and_preprocess_entry\n",
      "    extract_fingerprints(args.d, args.fpe, args.npfp, args.verify_dataset_integrity, args.clean, args.verbose)\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 47, in extract_fingerprints\n",
      "    extract_fingerprint_dataset(d, fingerprint_extractor_class, num_processes, check_dataset_integrity, clean,\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 30, in extract_fingerprint_dataset\n",
      "    verify_dataset_integrity(join(nnUNet_raw, dataset_name), num_processes)\n",
      "  File \"/home/jovyan/.local/lib/python3.10/site-packages/nnunetv2/experiment_planning/verify_dataset_integrity.py\", line 200, in verify_dataset_integrity\n",
      "    reader_writer_class = determine_reader_writer_from_dataset_json(dataset_json, dataset[dataset.keys().__iter__().__next__()]['images'][0])\n",
      "StopIteration\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    ".local/bin/nnUNetv2_plan_and_preprocess -d 400 --verify_dataset_integrity -np 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] 167330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export nnUNet_raw=\"/home/jovyan/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/home/jovyan/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/jovyan/nnUNet_results\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=7 .local/bin/nnUNetv2_train -device \"cuda\" 300 2d 0 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=2 .local/bin/nnUNetv2_train -device \"cuda\" 300 2d 1 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=3 .local/bin/nnUNetv2_train -device \"cuda\" 300 2d 2 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=4 .local/bin/nnUNetv2_train -device \"cuda\" 300 2d 3 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=5 .local/bin/nnUNetv2_train -device \"cuda\" 300 2d 4 & \n",
    "sleep 120\n",
    "wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 3d_low_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 308383\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-03-31 23:48:28.949747: Using torch.compile...\n",
      "2025-03-31 23:48:30.048236: do_dummy_2d_data_aug: False\n",
      "2025-03-31 23:48:30.051918: Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "2025-03-31 23:48:30.054425: The split file contains 5 splits.\n",
      "2025-03-31 23:48:30.055792: Desired fold for training: 0\n",
      "2025-03-31 23:48:30.057202: This split has 25 training and 7 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_lowres\n",
      " {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [120, 275, 275], 'spacing': [1.1626841073184357, 0.7375779739066625, 0.7375779739066625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset300_combined', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.3964845058, 0.3964845058], 'original_median_shape_after_transp': [224, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1843.0, 'mean': 341.65234375, 'median': 328.0, 'min': -370.0, 'percentile_00_5': 84.0, 'percentile_99_5': 754.0, 'std': 122.56533813476562}}} \n",
      "\n",
      "2025-03-31 23:48:32.319427: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-03-31 23:48:32.345757: \n",
      "2025-03-31 23:48:32.347899: Epoch 0\n",
      "2025-03-31 23:48:32.350913: Current learning rate: 0.01\n",
      "2025-04-01 09:44:55.898329: val_loss -0.8339\n",
      "2025-04-01 09:44:55.899694: Pseudo dice [0.8421]\n",
      "2025-04-01 09:44:55.900907: Epoch time: 286.56 s\n",
      "2025-04-01 09:44:57.353625: \n",
      "2025-04-01 09:44:57.355190: Epoch 94\n",
      "2025-04-01 09:44:57.356480: Current learning rate: 0.00079\n",
      "2025-04-01 09:49:47.717431: train_loss -0.872\n",
      "2025-04-01 09:49:47.719479: val_loss -0.8167\n",
      "2025-04-01 09:49:47.721289: Pseudo dice [0.8261]\n",
      "2025-04-01 09:49:47.723491: Epoch time: 290.37 s\n",
      "2025-04-01 09:49:49.723970: \n",
      "2025-04-01 09:49:49.727343: Epoch 95\n",
      "2025-04-01 09:49:49.729352: Current learning rate: 0.00067\n",
      "2025-04-01 09:54:36.911785: train_loss -0.8736\n",
      "2025-04-01 09:54:36.913955: val_loss -0.8174\n",
      "2025-04-01 09:54:36.915401: Pseudo dice [0.8283]\n",
      "2025-04-01 09:54:36.916836: Epoch time: 287.19 s\n",
      "2025-04-01 09:54:38.769014: \n",
      "2025-04-01 09:54:38.770931: Epoch 96\n",
      "2025-04-01 09:54:38.772627: Current learning rate: 0.00055\n",
      "2025-04-01 09:59:26.371344: train_loss -0.875\n",
      "2025-04-01 09:59:26.376349: val_loss -0.8304\n",
      "2025-04-01 09:59:26.378763: Pseudo dice [0.8446]\n",
      "2025-04-01 09:59:26.380743: Epoch time: 287.6 s\n",
      "2025-04-01 09:59:28.413378: \n",
      "2025-04-01 09:59:28.415271: Epoch 97\n",
      "2025-04-01 09:59:28.416912: Current learning rate: 0.00043\n",
      "2025-04-01 10:04:16.256879: train_loss -0.8725\n",
      "2025-04-01 10:04:16.260138: val_loss -0.8326\n",
      "2025-04-01 10:04:16.261521: Pseudo dice [0.8483]\n",
      "2025-04-01 10:04:16.263043: Epoch time: 287.85 s\n",
      "2025-04-01 10:04:18.180292: \n",
      "2025-04-01 10:04:18.181828: Epoch 98\n",
      "2025-04-01 10:04:18.183233: Current learning rate: 0.0003\n",
      "2025-04-01 10:09:06.130012: train_loss -0.875\n",
      "2025-04-01 10:09:06.133472: val_loss -0.8227\n",
      "2025-04-01 10:09:06.135841: Pseudo dice [0.8447]\n",
      "2025-04-01 10:09:06.137578: Epoch time: 287.95 s\n",
      "2025-04-01 10:09:07.886006: \n",
      "2025-04-01 10:09:07.888065: Epoch 99\n",
      "2025-04-01 10:09:07.890266: Current learning rate: 0.00016\n",
      "2025-04-01 10:13:54.825751: train_loss -0.8761\n",
      "2025-04-01 10:13:54.828860: val_loss -0.8354\n",
      "2025-04-01 10:13:54.830534: Pseudo dice [0.8474]\n",
      "2025-04-01 10:13:54.832077: Epoch time: 286.94 s\n",
      "2025-04-01 10:13:57.521718: Training done.\n",
      "2025-04-01 10:13:57.575223: Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "2025-04-01 10:13:57.578400: The split file contains 5 splits.\n",
      "2025-04-01 10:13:57.580086: Desired fold for training: 0\n",
      "2025-04-01 10:13:57.581852: This split has 25 training and 7 validation cases.\n",
      "2025-04-01 10:13:57.603938: predicting DISEASED_001\n",
      "2025-04-01 10:13:57.695772: DISEASED_001, shape torch.Size([1, 120, 268, 268]), rank 0\n",
      "2025-04-01 10:14:32.133966: predicting DISEASED_004\n",
      "2025-04-01 10:14:32.307868: DISEASED_004, shape torch.Size([1, 120, 339, 339]), rank 0\n",
      "2025-04-01 10:15:02.970394: predicting DISEASED_009\n",
      "2025-04-01 10:15:03.089074: DISEASED_009, shape torch.Size([1, 120, 323, 323]), rank 0\n",
      "2025-04-01 10:15:33.765038: predicting DISEASED_013\n",
      "2025-04-01 10:15:33.853841: DISEASED_013, shape torch.Size([1, 120, 274, 274]), rank 0\n",
      "2025-04-01 10:15:49.255183: predicting DISEASED_016\n",
      "2025-04-01 10:15:49.368726: DISEASED_016, shape torch.Size([1, 120, 325, 325]), rank 0\n",
      "2025-04-01 10:16:20.072132: predicting NORMAL_003\n",
      "2025-04-01 10:16:20.166089: NORMAL_003, shape torch.Size([1, 114, 266, 266]), rank 0\n",
      "2025-04-01 10:16:35.565063: predicting NORMAL_012\n",
      "2025-04-01 10:16:35.657878: NORMAL_012, shape torch.Size([1, 111, 256, 256]), rank 0\n",
      "2025-04-01 10:17:11.920171: Validation complete\n",
      "2025-04-01 10:17:11.921737: Mean Validation Dice:  0.7455136156290985\n",
      "[1]+  Done                    CUDA_VISIBLE_DEVICES=7 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_lowres 0\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export nnUNet_raw=\"/home/jovyan/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/home/jovyan/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/jovyan/nnUNet_results\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=7 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_lowres 0 &\n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=7 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_lowres 1 &\n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=5 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_lowres 2 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=6 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_lowres 3 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=7 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_lowres 4 & \n",
    "sleep 120\n",
    "wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 3d_full_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 157048\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "using port 55927\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:55927 (errno: 99 - Cannot assign requested address).\n",
      "I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "worker 1 oversample 1.0\n",
      "worker 1 batch_size 1\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "worker 0 oversample 0.0\n",
      "worker 0 batch_size 1\n",
      "2025-03-31 16:53:01.819678: Using torch.compile...\n",
      "Using torch.compile...\n",
      "do_dummy_2d_data_aug: False\n",
      "Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "The split file contains 5 splits.\n",
      "Desired fold for training: 0\n",
      "This split has 25 training and 7 validation cases.\n",
      "2025-03-31 16:53:03.096185: do_dummy_2d_data_aug: False\n",
      "2025-03-31 16:53:03.100107: Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "2025-03-31 16:53:03.103664: The split file contains 5 splits.\n",
      "2025-03-31 16:53:03.105274: Desired fold for training: 0\n",
      "2025-03-31 16:53:03.107399: This split has 25 training and 7 validation cases.\n",
      "using pin_memory on device 1\n",
      "using pin_memory on device 0\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export nnUNet_raw=\"/home/jovyan/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/home/jovyan/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/jovyan/nnUNet_results\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1,2 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_fullres 0 -num_gpus 2& \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=3,4 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_fullres 1 -num_gpus 2& \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=5,6 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_fullres 2 -num_gpus 2& \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=4 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_fullres 3 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=5 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_fullres 4 & \n",
    "sleep 120\n",
    "wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d_cascade_fullres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 88300\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "using port 60467\n",
      "I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "worker 1 oversample 1.0\n",
      "worker 1 batch_size 1\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "worker 0 oversample 0.0\n",
      "worker 0 batch_size 1\n",
      "Using torch.compile...\n",
      "2025-04-02 18:55:38.183250: Using torch.compile...\n",
      "do_dummy_2d_data_aug: False\n",
      "Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "The split file contains 5 splits.\n",
      "Desired fold for training: 2\n",
      "This split has 26 training and 6 validation cases.\n",
      "2025-04-02 18:55:44.102479: do_dummy_2d_data_aug: False\n",
      "2025-04-02 18:55:44.108184: Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "2025-04-02 18:55:44.113033: The split file contains 5 splits.\n",
      "2025-04-02 18:55:44.116151: Desired fold for training: 2\n",
      "2025-04-02 18:55:44.119182: This split has 26 training and 6 validation cases.\n",
      "using pin_memory on device 1\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 1\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_cascade_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [224.0, 512.0, 512.0], 'spacing': [0.625, 0.3964845058, 0.3964845058], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres', 'previous_stage': '3d_lowres'} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset300_combined', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.3964845058, 0.3964845058], 'original_median_shape_after_transp': [224, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1843.0, 'mean': 341.65234375, 'median': 328.0, 'min': -370.0, 'percentile_00_5': 84.0, 'percentile_99_5': 754.0, 'std': 122.56533813476562}}} \n",
      "\n",
      "Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-04-02 18:56:02.776780: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "\n",
      "Epoch 50\n",
      "Current learning rate: 0.00536\n",
      "2025-04-02 18:56:02.845285: \n",
      "2025-04-02 18:56:02.846904: Epoch 50\n",
      "2025-04-02 18:56:02.849110: Current learning rate: 0.00536\n",
      "[2] 99235\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "using port 50327\n",
      "[W socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:50327 (errno: 99 - Cannot assign requested address).\n",
      "I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "worker 1 oversample 1.0\n",
      "worker 1 batch_size 1\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "worker 0 oversample 0.0\n",
      "worker 0 batch_size 1\n",
      "Using torch.compile...\n",
      "2025-04-02 18:57:39.587030: Using torch.compile...\n",
      "do_dummy_2d_data_aug: False\n",
      "Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "The split file contains 5 splits.\n",
      "Desired fold for training: 3\n",
      "This split has 26 training and 6 validation cases.\n",
      "2025-04-02 18:57:41.942690: do_dummy_2d_data_aug: False\n",
      "2025-04-02 18:57:41.946007: Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "2025-04-02 18:57:41.949864: The split file contains 5 splits.\n",
      "2025-04-02 18:57:41.952387: Desired fold for training: 3\n",
      "2025-04-02 18:57:41.954743: This split has 26 training and 6 validation cases.\n",
      "using pin_memory on device 1\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 1\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_cascade_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [224.0, 512.0, 512.0], 'spacing': [0.625, 0.3964845058, 0.3964845058], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres', 'previous_stage': '3d_lowres'} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset300_combined', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.3964845058, 0.3964845058], 'original_median_shape_after_transp': [224, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1843.0, 'mean': 341.65234375, 'median': 328.0, 'min': -370.0, 'percentile_00_5': 84.0, 'percentile_99_5': 754.0, 'std': 122.56533813476562}}} \n",
      "\n",
      "2025-04-02 18:58:03.621128: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "\n",
      "Epoch 50\n",
      "Current learning rate: 0.00536\n",
      "2025-04-02 18:58:03.648993: \n",
      "2025-04-02 18:58:03.652227: Epoch 50\n",
      "2025-04-02 18:58:03.654705: Current learning rate: 0.00536\n",
      "[3] 110466\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "using port 41775\n",
      "train_loss -0.8248\n",
      "val_loss -0.8291\n",
      "Pseudo dice [0.8558]\n",
      "Epoch time: 211.64 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8593\n",
      "\n",
      "Epoch 51\n",
      "Current learning rate: 0.00526\n",
      "2025-04-02 18:59:34.417901: train_loss -0.8248\n",
      "2025-04-02 18:59:34.422059: val_loss -0.8291\n",
      "2025-04-02 18:59:34.424690: Pseudo dice [0.8558]\n",
      "2025-04-02 18:59:34.427460: Epoch time: 211.57 s\n",
      "2025-04-02 18:59:34.429493: Yayy! New best EMA pseudo Dice: 0.8593\n",
      "2025-04-02 18:59:36.769487: \n",
      "2025-04-02 18:59:36.772410: Epoch 51\n",
      "2025-04-02 18:59:36.776961: Current learning rate: 0.00526\n",
      "I am local rank 1. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "worker 1 oversample 1.0\n",
      "worker 1 batch_size 1\n",
      "I am local rank 0. 2 GPUs are available. The world size is 2.Setting device to cuda\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "worker 0 oversample 0.0\n",
      "worker 0 batch_size 1\n",
      "2025-04-02 18:59:40.342862: Using torch.compile...\n",
      "Using torch.compile...\n",
      "2025-04-02 18:59:43.037183: do_dummy_2d_data_aug: False\n",
      "2025-04-02 18:59:43.043993: Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "2025-04-02 18:59:43.049757: The split file contains 5 splits.\n",
      "2025-04-02 18:59:43.052473: Desired fold for training: 4\n",
      "2025-04-02 18:59:43.055430: This split has 26 training and 6 validation cases.\n",
      "do_dummy_2d_data_aug: False\n",
      "Using splits from existing split file: /home/jovyan/nnUNet_preprocessed/Dataset300_combined/splits_final.json\n",
      "The split file contains 5 splits.\n",
      "Desired fold for training: 4\n",
      "This split has 26 training and 6 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 1\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 1\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_cascade_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [224.0, 512.0, 512.0], 'spacing': [0.625, 0.3964845058, 0.3964845058], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres', 'previous_stage': '3d_lowres'} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset300_combined', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.3964845058, 0.3964845058], 'original_median_shape_after_transp': [224, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1843.0, 'mean': 341.65234375, 'median': 328.0, 'min': -370.0, 'percentile_00_5': 84.0, 'percentile_99_5': 754.0, 'std': 122.56533813476562}}} \n",
      "\n",
      "Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "\n",
      "Epoch 50\n",
      "Current learning rate: 0.00536\n",
      "2025-04-02 19:00:05.441661: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-04-02 19:00:05.479544: \n",
      "2025-04-02 19:00:05.525326: Epoch 50\n",
      "2025-04-02 19:00:05.527420: Current learning rate: 0.00536\n",
      "2025-04-02 19:01:39.261087: train_loss -0.8299\n",
      "2025-04-02 19:01:39.265345: val_loss -0.8522\n",
      "2025-04-02 19:01:39.267871: Pseudo dice [0.8705]\n",
      "2025-04-02 19:01:39.269934: Epoch time: 215.62 s\n",
      "train_loss -0.8299\n",
      "val_loss -0.8522\n",
      "Pseudo dice [0.8705]\n",
      "Epoch time: 215.65 s\n",
      "\n",
      "Epoch 51\n",
      "Current learning rate: 0.00526\n",
      "2025-04-02 19:01:40.952274: \n",
      "2025-04-02 19:01:40.953846: Epoch 51\n",
      "2025-04-02 19:01:40.955351: Current learning rate: 0.00526\n",
      "train_loss -0.8232\n",
      "val_loss -0.8363\n",
      "Pseudo dice [0.8659]\n",
      "Epoch time: 153.35 s\n",
      "Yayy! New best EMA pseudo Dice: 0.86\n",
      "\n",
      "Epoch 52\n",
      "Current learning rate: 0.00517\n",
      "2025-04-02 19:02:07.770583: train_loss -0.8232\n",
      "2025-04-02 19:02:07.773967: val_loss -0.8363\n",
      "2025-04-02 19:02:07.776083: Pseudo dice [0.8659]\n",
      "2025-04-02 19:02:07.777803: Epoch time: 151.0 s\n",
      "2025-04-02 19:02:07.779373: Yayy! New best EMA pseudo Dice: 0.86\n",
      "2025-04-02 19:02:10.238809: \n",
      "2025-04-02 19:02:10.241076: Epoch 52\n",
      "2025-04-02 19:02:10.244007: Current learning rate: 0.00517\n",
      "train_loss -0.816\n",
      "val_loss -0.8446\n",
      "Pseudo dice [0.8602]\n",
      "Epoch time: 216.31 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8486\n",
      "\n",
      "Epoch 51\n",
      "Current learning rate: 0.00526\n",
      "2025-04-02 19:03:41.760032: train_loss -0.816\n",
      "2025-04-02 19:03:41.763254: val_loss -0.8446\n",
      "2025-04-02 19:03:41.765700: Pseudo dice [0.8602]\n",
      "2025-04-02 19:03:41.767837: Epoch time: 216.28 s\n",
      "2025-04-02 19:03:41.769537: Yayy! New best EMA pseudo Dice: 0.8486\n",
      "2025-04-02 19:03:44.372577: \n",
      "2025-04-02 19:03:44.375493: Epoch 51\n",
      "2025-04-02 19:03:44.377861: Current learning rate: 0.00526\n",
      "train_loss -0.824\n",
      "val_loss -0.8548\n",
      "Pseudo dice [0.874]\n",
      "Epoch time: 153.47 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8667\n",
      "\n",
      "Epoch 52\n",
      "Current learning rate: 0.00517\n",
      "2025-04-02 19:04:12.747327: train_loss -0.824\n",
      "2025-04-02 19:04:12.751046: val_loss -0.8548\n",
      "2025-04-02 19:04:12.754356: Pseudo dice [0.874]\n",
      "2025-04-02 19:04:12.756184: Epoch time: 151.8 s\n",
      "2025-04-02 19:04:12.757715: Yayy! New best EMA pseudo Dice: 0.8667\n",
      "2025-04-02 19:04:15.014418: \n",
      "2025-04-02 19:04:15.016516: Epoch 52\n",
      "2025-04-02 19:04:15.018371: Current learning rate: 0.00517\n",
      "train_loss -0.8268\n",
      "val_loss -0.8287\n",
      "Pseudo dice [0.8526]\n",
      "Epoch time: 154.05 s\n",
      "\n",
      "Epoch 53\n",
      "Current learning rate: 0.00507\n",
      "2025-04-02 19:04:41.825430: train_loss -0.8268\n",
      "2025-04-02 19:04:41.829163: val_loss -0.8287\n",
      "2025-04-02 19:04:41.832172: Pseudo dice [0.8526]\n",
      "2025-04-02 19:04:41.834565: Epoch time: 151.59 s\n",
      "2025-04-02 19:04:43.645870: \n",
      "2025-04-02 19:04:43.648945: Epoch 53\n",
      "2025-04-02 19:04:43.651598: Current learning rate: 0.00507\n",
      "train_loss -0.8238\n",
      "val_loss -0.8187\n",
      "Pseudo dice [0.8506]\n",
      "Epoch time: 153.27 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8488\n",
      "2025-04-02 19:06:15.032645: train_loss -0.8238\n",
      "2025-04-02 19:06:15.038298: val_loss -0.8187\n",
      "\n",
      "Epoch 52\n",
      "Current learning rate: 0.00517\n",
      "2025-04-02 19:06:15.040206: Pseudo dice [0.8506]\n",
      "2025-04-02 19:06:15.048349: Epoch time: 150.66 s\n",
      "2025-04-02 19:06:15.052858: Yayy! New best EMA pseudo Dice: 0.8488\n",
      "2025-04-02 19:06:17.338846: \n",
      "2025-04-02 19:06:17.340321: Epoch 52\n",
      "2025-04-02 19:06:17.341880: Current learning rate: 0.00517\n",
      "train_loss -0.8201\n",
      "val_loss -0.8439\n",
      "Pseudo dice [0.8673]\n",
      "Epoch time: 154.14 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8667\n",
      "\n",
      "Epoch 53\n",
      "Current learning rate: 0.00507\n",
      "2025-04-02 19:06:46.891642: train_loss -0.8201\n",
      "2025-04-02 19:06:46.894531: val_loss -0.8439\n",
      "2025-04-02 19:06:46.898098: Pseudo dice [0.8673]\n",
      "2025-04-02 19:06:46.900711: Epoch time: 151.88 s\n",
      "2025-04-02 19:06:46.902560: Yayy! New best EMA pseudo Dice: 0.8667\n",
      "2025-04-02 19:06:49.125508: \n",
      "2025-04-02 19:06:49.134877: Epoch 53\n",
      "2025-04-02 19:06:49.140844: Current learning rate: 0.00507\n",
      "train_loss -0.8295\n",
      "val_loss -0.864\n",
      "Pseudo dice [0.879]\n",
      "Epoch time: 152.91 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8612\n",
      "\n",
      "Epoch 54\n",
      "Current learning rate: 0.00497\n",
      "2025-04-02 19:07:14.735552: train_loss -0.8295\n",
      "2025-04-02 19:07:14.738451: val_loss -0.864\n",
      "2025-04-02 19:07:14.739966: Pseudo dice [0.879]\n",
      "2025-04-02 19:07:14.748511: Epoch time: 151.09 s\n",
      "2025-04-02 19:07:14.751911: Yayy! New best EMA pseudo Dice: 0.8612\n",
      "2025-04-02 19:07:17.465087: \n",
      "2025-04-02 19:07:17.468199: Epoch 54\n",
      "2025-04-02 19:07:17.471280: Current learning rate: 0.00497\n",
      "train_loss -0.8244\n",
      "val_loss -0.8258\n",
      "Pseudo dice [0.856]\n",
      "Epoch time: 152.66 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8495\n",
      "\n",
      "Epoch 53\n",
      "Current learning rate: 0.00507\n",
      "2025-04-02 19:08:47.689585: train_loss -0.8244\n",
      "2025-04-02 19:08:47.776132: val_loss -0.8258\n",
      "2025-04-02 19:08:47.778990: Pseudo dice [0.856]\n",
      "2025-04-02 19:08:47.781553: Epoch time: 150.35 s\n",
      "2025-04-02 19:08:47.784493: Yayy! New best EMA pseudo Dice: 0.8495\n",
      "2025-04-02 19:08:50.770250: \n",
      "2025-04-02 19:08:50.776660: Epoch 53\n",
      "2025-04-02 19:08:50.783850: Current learning rate: 0.00507\n",
      "train_loss -0.8256\n",
      "val_loss -0.8566\n",
      "Pseudo dice [0.8781]\n",
      "Epoch time: 153.88 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8679\n",
      "\n",
      "Epoch 54\n",
      "Current learning rate: 0.00497\n",
      "2025-04-02 19:09:20.770648: train_loss -0.8256\n",
      "2025-04-02 19:09:20.849146: val_loss -0.8566\n",
      "2025-04-02 19:09:20.862552: Pseudo dice [0.8781]\n",
      "2025-04-02 19:09:20.865021: Epoch time: 151.65 s\n",
      "2025-04-02 19:09:20.866718: Yayy! New best EMA pseudo Dice: 0.8679\n",
      "2025-04-02 19:09:23.919541: \n",
      "2025-04-02 19:09:23.922641: Epoch 54\n",
      "2025-04-02 19:09:23.925324: Current learning rate: 0.00497\n",
      "train_loss -0.8229\n",
      "val_loss -0.83\n",
      "Pseudo dice [0.8523]\n",
      "Epoch time: 153.8 s\n",
      "\n",
      "Epoch 55\n",
      "Current learning rate: 0.00487\n",
      "2025-04-02 19:09:48.533183: train_loss -0.8229\n",
      "2025-04-02 19:09:48.537310: val_loss -0.83\n",
      "2025-04-02 19:09:48.541058: Pseudo dice [0.8523]\n",
      "2025-04-02 19:09:48.542902: Epoch time: 151.07 s\n",
      "2025-04-02 19:09:50.482101: \n",
      "2025-04-02 19:09:50.483458: Epoch 55\n",
      "2025-04-02 19:09:50.485044: Current learning rate: 0.00487\n",
      "train_loss -0.819\n",
      "val_loss -0.826\n",
      "Pseudo dice [0.8394]\n",
      "Epoch time: 153.77 s\n",
      "\n",
      "Epoch 54\n",
      "Current learning rate: 0.00497\n",
      "2025-04-02 19:11:21.457442: train_loss -0.819\n",
      "2025-04-02 19:11:21.465683: val_loss -0.826\n",
      "2025-04-02 19:11:21.468809: Pseudo dice [0.8394]\n",
      "2025-04-02 19:11:21.471337: Epoch time: 150.69 s\n",
      "2025-04-02 19:11:23.285089: \n",
      "2025-04-02 19:11:23.288859: Epoch 54\n",
      "2025-04-02 19:11:23.297370: Current learning rate: 0.00497\n",
      "train_loss -0.8207\n",
      "val_loss -0.853\n",
      "Pseudo dice [0.8721]\n",
      "Epoch time: 154.77 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8683\n",
      "\n",
      "Epoch 55\n",
      "Current learning rate: 0.00487\n",
      "2025-04-02 19:11:55.544638: train_loss -0.8207\n",
      "2025-04-02 19:11:55.577015: val_loss -0.853\n",
      "2025-04-02 19:11:55.579225: Pseudo dice [0.8721]\n",
      "2025-04-02 19:11:55.603196: Epoch time: 151.63 s\n",
      "2025-04-02 19:11:55.613413: Yayy! New best EMA pseudo Dice: 0.8683\n",
      "2025-04-02 19:11:58.063245: \n",
      "2025-04-02 19:11:58.082761: Epoch 55\n",
      "2025-04-02 19:11:58.092912: Current learning rate: 0.00487\n",
      "train_loss -0.8201\n",
      "val_loss -0.8412\n",
      "Pseudo dice [0.8657]\n",
      "Epoch time: 153.35 s\n",
      "\n",
      "Epoch 56\n",
      "Current learning rate: 0.00478\n",
      "2025-04-02 19:12:21.882015: train_loss -0.8201\n",
      "2025-04-02 19:12:21.884426: val_loss -0.8412\n",
      "2025-04-02 19:12:21.886528: Pseudo dice [0.8657]\n",
      "2025-04-02 19:12:21.888466: Epoch time: 151.4 s\n",
      "2025-04-02 19:12:24.274778: \n",
      "2025-04-02 19:12:24.280291: Epoch 56\n",
      "2025-04-02 19:12:24.281869: Current learning rate: 0.00478\n",
      "train_loss -0.8186\n",
      "val_loss -0.8299\n",
      "Pseudo dice [0.8513]\n",
      "Epoch time: 152.47 s\n",
      "\n",
      "Epoch 55\n",
      "Current learning rate: 0.00487\n",
      "2025-04-02 19:13:53.923876: train_loss -0.8186\n",
      "2025-04-02 19:13:53.930614: val_loss -0.8299\n",
      "2025-04-02 19:13:53.934246: Pseudo dice [0.8513]\n",
      "2025-04-02 19:13:53.937297: Epoch time: 150.64 s\n",
      "2025-04-02 19:13:55.547957: \n",
      "2025-04-02 19:13:55.574067: Epoch 55\n",
      "2025-04-02 19:13:55.576563: Current learning rate: 0.00487\n",
      "train_loss -0.8202\n",
      "val_loss -0.8503\n",
      "Pseudo dice [0.8697]\n",
      "Epoch time: 154.01 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8684\n",
      "\n",
      "Epoch 56\n",
      "Current learning rate: 0.00478\n",
      "2025-04-02 19:14:29.552729: train_loss -0.8202\n",
      "2025-04-02 19:14:29.598139: val_loss -0.8503\n",
      "2025-04-02 19:14:29.641005: Pseudo dice [0.8697]\n",
      "2025-04-02 19:14:29.645341: Epoch time: 151.49 s\n",
      "2025-04-02 19:14:29.649132: Yayy! New best EMA pseudo Dice: 0.8684\n",
      "2025-04-02 19:14:32.814997: \n",
      "2025-04-02 19:14:32.818569: Epoch 56\n",
      "2025-04-02 19:14:32.822021: Current learning rate: 0.00478\n",
      "train_loss -0.8316\n",
      "val_loss -0.8443\n",
      "Pseudo dice [0.8727]\n",
      "Epoch time: 153.36 s\n",
      "Yayy! New best EMA pseudo Dice: 0.862\n",
      "2025-04-02 19:14:55.242696: train_loss -0.8316\n",
      "\n",
      "Epoch 57\n",
      "Current learning rate: 0.00468\n",
      "2025-04-02 19:14:55.245150: val_loss -0.8443\n",
      "2025-04-02 19:14:55.246629: Pseudo dice [0.8727]\n",
      "2025-04-02 19:14:55.247927: Epoch time: 150.98 s\n",
      "2025-04-02 19:14:55.249315: Yayy! New best EMA pseudo Dice: 0.862\n",
      "2025-04-02 19:14:57.789319: \n",
      "2025-04-02 19:14:57.803262: Epoch 57\n",
      "2025-04-02 19:14:57.820159: Current learning rate: 0.00468\n",
      "train_loss -0.8284\n",
      "val_loss -0.8224\n",
      "Pseudo dice [0.8375]\n",
      "Epoch time: 151.84 s\n",
      "\n",
      "Epoch 56\n",
      "Current learning rate: 0.00478\n",
      "2025-04-02 19:16:25.761808: train_loss -0.8284\n",
      "2025-04-02 19:16:25.765103: val_loss -0.8224\n",
      "2025-04-02 19:16:25.767162: Pseudo dice [0.8375]\n",
      "2025-04-02 19:16:25.777204: Epoch time: 150.22 s\n",
      "2025-04-02 19:16:28.145959: \n",
      "2025-04-02 19:16:28.150858: Epoch 56\n",
      "2025-04-02 19:16:28.161679: Current learning rate: 0.00478\n",
      "train_loss -0.8201\n",
      "val_loss -0.8591\n",
      "Pseudo dice [0.873]\n",
      "Epoch time: 154.33 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8689\n",
      "\n",
      "Epoch 57\n",
      "Current learning rate: 0.00468\n",
      "2025-04-02 19:17:03.879159: train_loss -0.8201\n",
      "2025-04-02 19:17:03.882646: val_loss -0.8591\n",
      "2025-04-02 19:17:03.884980: Pseudo dice [0.873]\n",
      "2025-04-02 19:17:03.886727: Epoch time: 151.07 s\n",
      "2025-04-02 19:17:03.888127: Yayy! New best EMA pseudo Dice: 0.8689\n",
      "2025-04-02 19:17:06.180069: \n",
      "2025-04-02 19:17:06.182188: Epoch 57\n",
      "2025-04-02 19:17:06.184869: Current learning rate: 0.00468\n",
      "train_loss -0.828\n",
      "val_loss -0.8308\n",
      "Pseudo dice [0.8553]\n",
      "Epoch time: 153.01 s\n",
      "\n",
      "Epoch 58\n",
      "Current learning rate: 0.00458\n",
      "2025-04-02 19:17:28.249766: train_loss -0.828\n",
      "2025-04-02 19:17:28.252495: val_loss -0.8308\n",
      "2025-04-02 19:17:28.254846: Pseudo dice [0.8553]\n",
      "2025-04-02 19:17:28.256845: Epoch time: 150.46 s\n",
      "2025-04-02 19:17:29.852216: \n",
      "2025-04-02 19:17:29.854808: Epoch 58\n",
      "2025-04-02 19:17:29.857926: Current learning rate: 0.00458\n",
      "train_loss -0.8251\n",
      "val_loss -0.834\n",
      "Pseudo dice [0.851]\n",
      "Epoch time: 152.76 s\n",
      "\n",
      "Epoch 57\n",
      "Current learning rate: 0.00468\n",
      "2025-04-02 19:18:58.524601: train_loss -0.8251\n",
      "2025-04-02 19:18:58.527871: val_loss -0.834\n",
      "2025-04-02 19:18:58.529620: Pseudo dice [0.851]\n",
      "2025-04-02 19:18:58.531568: Epoch time: 150.38 s\n",
      "2025-04-02 19:19:00.201275: \n",
      "2025-04-02 19:19:00.204022: Epoch 57\n",
      "2025-04-02 19:19:00.207086: Current learning rate: 0.00468\n",
      "train_loss -0.82\n",
      "val_loss -0.8341\n",
      "Pseudo dice [0.865]\n",
      "Epoch time: 153.35 s\n",
      "\n",
      "Epoch 58\n",
      "Current learning rate: 0.00458\n",
      "2025-04-02 19:19:37.225397: train_loss -0.82\n",
      "2025-04-02 19:19:37.228461: val_loss -0.8341\n",
      "2025-04-02 19:19:37.230820: Pseudo dice [0.865]\n",
      "2025-04-02 19:19:37.233076: Epoch time: 151.05 s\n",
      "2025-04-02 19:19:38.879008: \n",
      "2025-04-02 19:19:38.882314: Epoch 58\n",
      "2025-04-02 19:19:38.886089: Current learning rate: 0.00458\n",
      "train_loss -0.8351\n",
      "val_loss -0.84\n",
      "Pseudo dice [0.8635]\n",
      "Epoch time: 152.24 s\n",
      "\n",
      "Epoch 59\n",
      "Current learning rate: 0.00448\n",
      "2025-04-02 19:20:00.487893: train_loss -0.8351\n",
      "2025-04-02 19:20:00.496541: val_loss -0.84\n",
      "2025-04-02 19:20:00.500293: Pseudo dice [0.8635]\n",
      "2025-04-02 19:20:00.503137: Epoch time: 150.64 s\n",
      "2025-04-02 19:20:02.135170: \n",
      "2025-04-02 19:20:02.138714: Epoch 59\n",
      "2025-04-02 19:20:02.143130: Current learning rate: 0.00448\n",
      "train_loss -0.823\n",
      "val_loss -0.8318\n",
      "Pseudo dice [0.8549]\n",
      "Epoch time: 152.02 s\n",
      "2025-04-02 19:21:30.549372: train_loss -0.823\n",
      "\n",
      "Epoch 58\n",
      "Current learning rate: 0.00458\n",
      "2025-04-02 19:21:30.551466: val_loss -0.8318\n",
      "2025-04-02 19:21:30.553178: Pseudo dice [0.8549]\n",
      "2025-04-02 19:21:30.554760: Epoch time: 150.35 s\n",
      "2025-04-02 19:21:32.148058: \n",
      "2025-04-02 19:21:32.150977: Epoch 58\n",
      "2025-04-02 19:21:32.153923: Current learning rate: 0.00458\n",
      "train_loss -0.8141\n",
      "val_loss -0.8463\n",
      "Pseudo dice [0.8695]\n",
      "Epoch time: 152.82 s\n",
      "2025-04-02 19:22:10.046791: train_loss -0.8141\n",
      "2025-04-02 19:22:10.049637: val_loss -0.8463\n",
      "\n",
      "Epoch 59\n",
      "Current learning rate: 0.00448\n",
      "2025-04-02 19:22:10.051630: Pseudo dice [0.8695]\n",
      "2025-04-02 19:22:10.054365: Epoch time: 151.17 s\n",
      "2025-04-02 19:22:11.713289: \n",
      "2025-04-02 19:22:11.714944: Epoch 59\n",
      "2025-04-02 19:22:11.716211: Current learning rate: 0.00448\n",
      "train_loss -0.8304\n",
      "val_loss -0.838\n",
      "Pseudo dice [0.8566]\n",
      "Epoch time: 152.25 s\n",
      "\n",
      "Epoch 60\n",
      "Current learning rate: 0.00438\n",
      "2025-04-02 19:22:32.732959: train_loss -0.8304\n",
      "2025-04-02 19:22:32.735931: val_loss -0.838\n",
      "2025-04-02 19:22:32.737671: Pseudo dice [0.8566]\n",
      "2025-04-02 19:22:32.739626: Epoch time: 150.6 s\n",
      "2025-04-02 19:22:34.464295: \n",
      "2025-04-02 19:22:34.467319: Epoch 60\n",
      "2025-04-02 19:22:34.470349: Current learning rate: 0.00438\n",
      "train_loss -0.8271\n",
      "val_loss -0.8092\n",
      "Pseudo dice [0.8404]\n",
      "Epoch time: 151.31 s\n",
      "\n",
      "Epoch 59\n",
      "Current learning rate: 0.00448\n",
      "2025-04-02 19:24:01.864125: train_loss -0.8271\n",
      "2025-04-02 19:24:01.867173: val_loss -0.8092\n",
      "2025-04-02 19:24:01.868777: Pseudo dice [0.8404]\n",
      "2025-04-02 19:24:01.870332: Epoch time: 149.72 s\n",
      "2025-04-02 19:24:03.528096: \n",
      "2025-04-02 19:24:03.529907: Epoch 59\n",
      "2025-04-02 19:24:03.531417: Current learning rate: 0.00448\n",
      "train_loss -0.8121\n",
      "val_loss -0.8585\n",
      "Pseudo dice [0.877]\n",
      "Epoch time: 152.95 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8694\n",
      "\n",
      "Epoch 60\n",
      "Current learning rate: 0.00438\n",
      "2025-04-02 19:24:43.001615: train_loss -0.8121\n",
      "2025-04-02 19:24:43.009151: val_loss -0.8585\n",
      "2025-04-02 19:24:43.015701: Pseudo dice [0.877]\n",
      "2025-04-02 19:24:43.020164: Epoch time: 151.29 s\n",
      "2025-04-02 19:24:43.024888: Yayy! New best EMA pseudo Dice: 0.8694\n",
      "2025-04-02 19:24:45.292754: \n",
      "2025-04-02 19:24:45.294574: Epoch 60\n",
      "2025-04-02 19:24:45.295978: Current learning rate: 0.00438\n",
      "train_loss -0.8248\n",
      "val_loss -0.8473\n",
      "Pseudo dice [0.8669]\n",
      "Epoch time: 152.41 s\n",
      "\n",
      "Epoch 61\n",
      "Current learning rate: 0.00429\n",
      "2025-04-02 19:25:05.139161: train_loss -0.8248\n",
      "2025-04-02 19:25:05.142920: val_loss -0.8473\n",
      "2025-04-02 19:25:05.145056: Pseudo dice [0.8669]\n",
      "2025-04-02 19:25:05.147359: Epoch time: 150.68 s\n",
      "2025-04-02 19:25:06.870527: \n",
      "2025-04-02 19:25:06.873853: Epoch 61\n",
      "2025-04-02 19:25:06.876623: Current learning rate: 0.00429\n",
      "train_loss -0.8192\n",
      "val_loss -0.8318\n",
      "Pseudo dice [0.8547]\n",
      "Epoch time: 151.47 s\n",
      "\n",
      "Epoch 60\n",
      "Current learning rate: 0.00438\n",
      "2025-04-02 19:26:33.339109: train_loss -0.8192\n",
      "2025-04-02 19:26:33.342064: val_loss -0.8318\n",
      "2025-04-02 19:26:33.343357: Pseudo dice [0.8547]\n",
      "2025-04-02 19:26:33.344682: Epoch time: 149.81 s\n",
      "2025-04-02 19:26:35.032481: \n",
      "2025-04-02 19:26:35.036808: Epoch 60\n",
      "2025-04-02 19:26:35.040755: Current learning rate: 0.00438\n",
      "train_loss -0.8219\n",
      "val_loss -0.8528\n",
      "Pseudo dice [0.8721]\n",
      "Epoch time: 153.6 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8697\n",
      "\n",
      "Epoch 61\n",
      "Current learning rate: 0.00429\n",
      "2025-04-02 19:27:16.607102: train_loss -0.8219\n",
      "2025-04-02 19:27:16.610481: val_loss -0.8528\n",
      "2025-04-02 19:27:16.612947: Pseudo dice [0.8721]\n",
      "2025-04-02 19:27:16.616048: Epoch time: 151.32 s\n",
      "2025-04-02 19:27:16.617692: Yayy! New best EMA pseudo Dice: 0.8697\n",
      "2025-04-02 19:27:18.984169: \n",
      "2025-04-02 19:27:18.987556: Epoch 61\n",
      "2025-04-02 19:27:18.990611: Current learning rate: 0.00429\n",
      "train_loss -0.8351\n",
      "val_loss -0.848\n",
      "Pseudo dice [0.8681]\n",
      "Epoch time: 152.44 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8623\n",
      "\n",
      "Epoch 62\n",
      "Current learning rate: 0.00419\n",
      "2025-04-02 19:27:37.580136: train_loss -0.8351\n",
      "2025-04-02 19:27:37.584243: val_loss -0.848\n",
      "2025-04-02 19:27:37.589089: Pseudo dice [0.8681]\n",
      "2025-04-02 19:27:37.591283: Epoch time: 150.71 s\n",
      "2025-04-02 19:27:37.592789: Yayy! New best EMA pseudo Dice: 0.8623\n",
      "2025-04-02 19:27:39.994401: \n",
      "2025-04-02 19:27:39.997403: Epoch 62\n",
      "2025-04-02 19:27:40.000234: Current learning rate: 0.00419\n",
      "train_loss -0.8321\n",
      "val_loss -0.824\n",
      "Pseudo dice [0.8476]\n",
      "Epoch time: 151.89 s\n",
      "\n",
      "Epoch 61\n",
      "Current learning rate: 0.00429\n",
      "2025-04-02 19:29:05.226241: train_loss -0.8321\n",
      "2025-04-02 19:29:05.230979: val_loss -0.824\n",
      "2025-04-02 19:29:05.233990: Pseudo dice [0.8476]\n",
      "2025-04-02 19:29:05.236037: Epoch time: 150.2 s\n",
      "2025-04-02 19:29:06.957585: \n",
      "2025-04-02 19:29:06.960593: Epoch 61\n",
      "2025-04-02 19:29:06.963729: Current learning rate: 0.00429\n",
      "train_loss -0.8207\n",
      "val_loss -0.8598\n",
      "Pseudo dice [0.8788]\n",
      "Epoch time: 153.55 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8706\n",
      "2025-04-02 19:29:50.162115: train_loss -0.8207\n",
      "\n",
      "Epoch 62\n",
      "Current learning rate: 0.00419\n",
      "2025-04-02 19:29:50.164511: val_loss -0.8598\n",
      "2025-04-02 19:29:50.167587: Pseudo dice [0.8788]\n",
      "2025-04-02 19:29:50.169132: Epoch time: 151.18 s\n",
      "2025-04-02 19:29:50.170890: Yayy! New best EMA pseudo Dice: 0.8706\n",
      "2025-04-02 19:29:52.567654: \n",
      "2025-04-02 19:29:52.570725: Epoch 62\n",
      "2025-04-02 19:29:52.573563: Current learning rate: 0.00419\n",
      "train_loss -0.8297\n",
      "val_loss -0.8542\n",
      "Pseudo dice [0.8714]\n",
      "Epoch time: 153.17 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8632\n",
      "\n",
      "Epoch 63\n",
      "Current learning rate: 0.00409\n",
      "2025-04-02 19:30:10.753889: train_loss -0.8297\n",
      "2025-04-02 19:30:10.758385: val_loss -0.8542\n",
      "2025-04-02 19:30:10.761274: Pseudo dice [0.8714]\n",
      "2025-04-02 19:30:10.763478: Epoch time: 150.76 s\n",
      "2025-04-02 19:30:10.765242: Yayy! New best EMA pseudo Dice: 0.8632\n",
      "2025-04-02 19:30:13.070036: \n",
      "2025-04-02 19:30:13.085505: Epoch 63\n",
      "2025-04-02 19:30:13.088007: Current learning rate: 0.00409\n",
      "train_loss -0.8319\n",
      "val_loss -0.8137\n",
      "Pseudo dice [0.8496]\n",
      "Epoch time: 152.27 s\n",
      "\n",
      "Epoch 62\n",
      "Current learning rate: 0.00419\n",
      "2025-04-02 19:31:37.492897: train_loss -0.8319\n",
      "2025-04-02 19:31:37.496615: val_loss -0.8137\n",
      "2025-04-02 19:31:37.498896: Pseudo dice [0.8496]\n",
      "2025-04-02 19:31:37.500993: Epoch time: 150.54 s\n",
      "2025-04-02 19:31:39.169257: \n",
      "2025-04-02 19:31:39.175061: Epoch 62\n",
      "2025-04-02 19:31:39.182716: Current learning rate: 0.00419\n",
      "train_loss -0.8157\n",
      "val_loss -0.8523\n",
      "Pseudo dice [0.8762]\n",
      "Epoch time: 153.48 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8712\n",
      "\n",
      "Epoch 63\n",
      "Current learning rate: 0.00409\n",
      "2025-04-02 19:32:23.644757: train_loss -0.8157\n",
      "2025-04-02 19:32:23.647618: val_loss -0.8523\n",
      "2025-04-02 19:32:23.649208: Pseudo dice [0.8762]\n",
      "2025-04-02 19:32:23.651281: Epoch time: 151.08 s\n",
      "2025-04-02 19:32:23.652717: Yayy! New best EMA pseudo Dice: 0.8712\n",
      "2025-04-02 19:32:26.026344: \n",
      "2025-04-02 19:32:26.030032: Epoch 63\n",
      "2025-04-02 19:32:26.033202: Current learning rate: 0.00409\n",
      "train_loss -0.823\n",
      "val_loss -0.8138\n",
      "Pseudo dice [0.8376]\n",
      "Epoch time: 153.3 s\n",
      "\n",
      "Epoch 64\n",
      "Current learning rate: 0.00399\n",
      "2025-04-02 19:32:44.051265: train_loss -0.823\n",
      "2025-04-02 19:32:44.055320: val_loss -0.8138\n",
      "2025-04-02 19:32:44.057814: Pseudo dice [0.8376]\n",
      "2025-04-02 19:32:44.060345: Epoch time: 150.98 s\n",
      "2025-04-02 19:32:45.821052: \n",
      "2025-04-02 19:32:45.824597: Epoch 64\n",
      "2025-04-02 19:32:45.827901: Current learning rate: 0.00399\n",
      "train_loss -0.8338\n",
      "val_loss -0.8178\n",
      "Pseudo dice [0.8475]\n",
      "Epoch time: 152.09 s\n",
      "\n",
      "Epoch 63\n",
      "Current learning rate: 0.00409\n",
      "2025-04-02 19:34:09.581949: train_loss -0.8338\n",
      "2025-04-02 19:34:09.585132: val_loss -0.8178\n",
      "2025-04-02 19:34:09.587564: Pseudo dice [0.8475]\n",
      "2025-04-02 19:34:09.589652: Epoch time: 150.42 s\n",
      "2025-04-02 19:34:11.187712: \n",
      "2025-04-02 19:34:11.191475: Epoch 63\n",
      "2025-04-02 19:34:11.195501: Current learning rate: 0.00409\n",
      "train_loss -0.8259\n",
      "val_loss -0.8501\n",
      "Pseudo dice [0.8709]\n",
      "Epoch time: 153.73 s\n",
      "\n",
      "Epoch 64\n",
      "Current learning rate: 0.00399\n",
      "2025-04-02 19:34:57.375096: train_loss -0.8259\n",
      "2025-04-02 19:34:57.379326: val_loss -0.8501\n",
      "2025-04-02 19:34:57.381748: Pseudo dice [0.8709]\n",
      "2025-04-02 19:34:57.384999: Epoch time: 151.35 s\n",
      "2025-04-02 19:34:59.029204: \n",
      "2025-04-02 19:34:59.032177: Epoch 64\n",
      "2025-04-02 19:34:59.035274: Current learning rate: 0.00399\n",
      "train_loss -0.8355\n",
      "val_loss -0.855\n",
      "Pseudo dice [0.8759]\n",
      "Epoch time: 152.73 s\n",
      "\n",
      "Epoch 65\n",
      "Current learning rate: 0.00389\n",
      "2025-04-02 19:35:16.785099: train_loss -0.8355\n",
      "2025-04-02 19:35:16.790227: val_loss -0.855\n",
      "2025-04-02 19:35:16.812608: Pseudo dice [0.8759]\n",
      "2025-04-02 19:35:16.814589: Epoch time: 150.97 s\n",
      "2025-04-02 19:35:18.458272: \n",
      "2025-04-02 19:35:18.461077: Epoch 65\n",
      "2025-04-02 19:35:18.464097: Current learning rate: 0.00389\n",
      "train_loss -0.8434\n",
      "val_loss -0.8171\n",
      "Pseudo dice [0.8314]\n",
      "Epoch time: 152.19 s\n",
      "\n",
      "Epoch 64\n",
      "Current learning rate: 0.00399\n",
      "2025-04-02 19:36:41.776580: train_loss -0.8434\n",
      "2025-04-02 19:36:41.780972: val_loss -0.8171\n",
      "2025-04-02 19:36:41.784165: Pseudo dice [0.8314]\n",
      "2025-04-02 19:36:41.786390: Epoch time: 150.59 s\n",
      "2025-04-02 19:36:43.567373: \n",
      "2025-04-02 19:36:43.570187: Epoch 64\n",
      "2025-04-02 19:36:43.575562: Current learning rate: 0.00399\n",
      "train_loss -0.8242\n",
      "val_loss -0.8502\n",
      "Pseudo dice [0.8712]\n",
      "Epoch time: 152.92 s\n",
      "\n",
      "Epoch 65\n",
      "Current learning rate: 0.00389\n",
      "2025-04-02 19:37:30.300830: train_loss -0.8242\n",
      "2025-04-02 19:37:30.306033: val_loss -0.8502\n",
      "2025-04-02 19:37:30.308962: Pseudo dice [0.8712]\n",
      "2025-04-02 19:37:30.311355: Epoch time: 151.27 s\n",
      "2025-04-02 19:37:31.997245: \n",
      "2025-04-02 19:37:32.000582: Epoch 65\n",
      "2025-04-02 19:37:32.004354: Current learning rate: 0.00389\n",
      "train_loss -0.8309\n",
      "val_loss -0.8312\n",
      "Pseudo dice [0.8621]\n",
      "Epoch time: 152.69 s\n",
      "\n",
      "Epoch 66\n",
      "Current learning rate: 0.00379\n",
      "2025-04-02 19:37:49.478339: train_loss -0.8309\n",
      "2025-04-02 19:37:49.482312: val_loss -0.8312\n",
      "2025-04-02 19:37:49.484884: Pseudo dice [0.8621]\n",
      "2025-04-02 19:37:49.488363: Epoch time: 151.02 s\n",
      "2025-04-02 19:37:51.180179: \n",
      "2025-04-02 19:37:51.182996: Epoch 66\n",
      "2025-04-02 19:37:51.185096: Current learning rate: 0.00379\n",
      "train_loss -0.8291\n",
      "val_loss -0.8236\n",
      "Pseudo dice [0.8518]\n",
      "Epoch time: 152.33 s\n",
      "\n",
      "Epoch 65\n",
      "Current learning rate: 0.00389\n",
      "2025-04-02 19:39:14.103112: train_loss -0.8291\n",
      "2025-04-02 19:39:14.106606: val_loss -0.8236\n",
      "2025-04-02 19:39:14.109191: Pseudo dice [0.8518]\n",
      "2025-04-02 19:39:14.111075: Epoch time: 150.54 s\n",
      "2025-04-02 19:39:15.860911: \n",
      "2025-04-02 19:39:15.863695: Epoch 65\n",
      "2025-04-02 19:39:15.865927: Current learning rate: 0.00389\n",
      "train_loss -0.8254\n",
      "val_loss -0.8521\n",
      "Pseudo dice [0.8735]\n",
      "Epoch time: 153.46 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8714\n",
      "\n",
      "Epoch 66\n",
      "Current learning rate: 0.00379\n",
      "2025-04-02 19:40:03.760224: train_loss -0.8254\n",
      "2025-04-02 19:40:03.777508: val_loss -0.8521\n",
      "2025-04-02 19:40:03.783208: Pseudo dice [0.8735]\n",
      "2025-04-02 19:40:03.792582: Epoch time: 151.77 s\n",
      "2025-04-02 19:40:03.800113: Yayy! New best EMA pseudo Dice: 0.8714\n",
      "2025-04-02 19:40:06.193352: \n",
      "2025-04-02 19:40:06.196531: Epoch 66\n",
      "2025-04-02 19:40:06.199024: Current learning rate: 0.00379\n",
      "train_loss -0.8252\n",
      "val_loss -0.8527\n",
      "Pseudo dice [0.8756]\n",
      "Epoch time: 152.65 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8635\n",
      "\n",
      "Epoch 67\n",
      "Current learning rate: 0.00369\n",
      "2025-04-02 19:40:22.130673: train_loss -0.8252\n",
      "2025-04-02 19:40:22.134165: val_loss -0.8527\n",
      "2025-04-02 19:40:22.135752: Pseudo dice [0.8756]\n",
      "2025-04-02 19:40:22.138137: Epoch time: 150.95 s\n",
      "2025-04-02 19:40:22.139750: Yayy! New best EMA pseudo Dice: 0.8635\n",
      "2025-04-02 19:40:24.396000: \n",
      "2025-04-02 19:40:24.398998: Epoch 67\n",
      "2025-04-02 19:40:24.402680: Current learning rate: 0.00369\n",
      "train_loss -0.8246\n",
      "val_loss -0.8201\n",
      "Pseudo dice [0.8479]\n",
      "Epoch time: 151.77 s\n",
      "\n",
      "Epoch 66\n",
      "2025-04-02 19:41:45.877168: train_loss -0.8246\n",
      "Current learning rate: 0.00379\n",
      "2025-04-02 19:41:45.880054: val_loss -0.8201\n",
      "2025-04-02 19:41:45.881956: Pseudo dice [0.8479]\n",
      "2025-04-02 19:41:45.887164: Epoch time: 150.02 s\n",
      "2025-04-02 19:41:47.511557: \n",
      "2025-04-02 19:41:47.514424: Epoch 66\n",
      "2025-04-02 19:41:47.517731: Current learning rate: 0.00379\n",
      "train_loss -0.8209\n",
      "val_loss -0.8567\n",
      "Pseudo dice [0.8735]\n",
      "Epoch time: 153.95 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8716\n",
      "\n",
      "Epoch 67\n",
      "Current learning rate: 0.00369\n",
      "2025-04-02 19:42:37.707829: train_loss -0.8209\n",
      "2025-04-02 19:42:37.711560: val_loss -0.8567\n",
      "2025-04-02 19:42:37.713668: Pseudo dice [0.8735]\n",
      "2025-04-02 19:42:37.716162: Epoch time: 151.52 s\n",
      "2025-04-02 19:42:37.717628: Yayy! New best EMA pseudo Dice: 0.8716\n",
      "2025-04-02 19:42:40.105326: \n",
      "2025-04-02 19:42:40.109119: Epoch 67\n",
      "2025-04-02 19:42:40.112144: Current learning rate: 0.00369\n",
      "train_loss -0.8416\n",
      "val_loss -0.8366\n",
      "Pseudo dice [0.8583]\n",
      "Epoch time: 153.27 s\n",
      "\n",
      "Epoch 68\n",
      "Current learning rate: 0.00359\n",
      "2025-04-02 19:42:55.396405: train_loss -0.8416\n",
      "2025-04-02 19:42:55.400310: val_loss -0.8366\n",
      "2025-04-02 19:42:55.401662: Pseudo dice [0.8583]\n",
      "2025-04-02 19:42:55.404181: Epoch time: 151.0 s\n",
      "2025-04-02 19:42:58.016408: \n",
      "2025-04-02 19:42:58.018981: Epoch 68\n",
      "2025-04-02 19:42:58.021134: Current learning rate: 0.00359\n",
      "train_loss -0.8394\n",
      "val_loss -0.8346\n",
      "Pseudo dice [0.8543]\n",
      "Epoch time: 151.98 s\n",
      "\n",
      "Epoch 67\n",
      "Current learning rate: 0.00369\n",
      "2025-04-02 19:44:17.856534: train_loss -0.8394\n",
      "2025-04-02 19:44:17.860705: val_loss -0.8346\n",
      "2025-04-02 19:44:17.863400: Pseudo dice [0.8543]\n",
      "2025-04-02 19:44:17.866054: Epoch time: 150.35 s\n",
      "2025-04-02 19:44:19.546453: \n",
      "2025-04-02 19:44:19.549521: Epoch 67\n",
      "2025-04-02 19:44:19.552916: Current learning rate: 0.00369\n",
      "train_loss -0.8351\n",
      "val_loss -0.843\n",
      "Pseudo dice [0.8676]\n",
      "Epoch time: 153.77 s\n",
      "\n",
      "Epoch 68\n",
      "Current learning rate: 0.00359\n",
      "2025-04-02 19:45:11.481950: train_loss -0.8351\n",
      "2025-04-02 19:45:11.484842: val_loss -0.843\n",
      "2025-04-02 19:45:11.486667: Pseudo dice [0.8676]\n",
      "2025-04-02 19:45:11.489014: Epoch time: 151.38 s\n",
      "2025-04-02 19:45:14.169835: \n",
      "2025-04-02 19:45:14.171991: Epoch 68\n",
      "2025-04-02 19:45:14.174223: Current learning rate: 0.00359\n",
      "train_loss -0.8358\n",
      "val_loss -0.84\n",
      "Pseudo dice [0.8602]\n",
      "Epoch time: 153.4 s\n",
      "\n",
      "Epoch 69\n",
      "Current learning rate: 0.00349\n",
      "2025-04-02 19:45:28.795751: train_loss -0.8358\n",
      "2025-04-02 19:45:28.799728: val_loss -0.84\n",
      "2025-04-02 19:45:28.801992: Pseudo dice [0.8602]\n",
      "2025-04-02 19:45:28.804474: Epoch time: 150.78 s\n",
      "2025-04-02 19:45:30.506282: \n",
      "2025-04-02 19:45:30.509134: Epoch 69\n",
      "2025-04-02 19:45:30.512099: Current learning rate: 0.00349\n",
      "train_loss -0.8396\n",
      "val_loss -0.8243\n",
      "Pseudo dice [0.8514]\n",
      "Epoch time: 151.96 s\n",
      "\n",
      "Epoch 68\n",
      "Current learning rate: 0.00359\n",
      "2025-04-02 19:46:49.820576: train_loss -0.8396\n",
      "2025-04-02 19:46:49.823862: val_loss -0.8243\n",
      "2025-04-02 19:46:49.825499: Pseudo dice [0.8514]\n",
      "2025-04-02 19:46:49.828597: Epoch time: 150.28 s\n",
      "2025-04-02 19:46:52.066629: \n",
      "2025-04-02 19:46:52.068890: Epoch 68\n",
      "2025-04-02 19:46:52.070873: Current learning rate: 0.00359\n",
      "train_loss -0.8328\n",
      "val_loss -0.8413\n",
      "Pseudo dice [0.8611]\n",
      "Epoch time: 154.16 s\n",
      "2025-04-02 19:47:45.642628: train_loss -0.8328\n",
      "\n",
      "Epoch 69\n",
      "Current learning rate: 0.00349\n",
      "2025-04-02 19:47:45.645043: val_loss -0.8413\n",
      "2025-04-02 19:47:45.647435: Pseudo dice [0.8611]\n",
      "2025-04-02 19:47:45.649361: Epoch time: 151.47 s\n",
      "2025-04-02 19:47:47.363410: \n",
      "2025-04-02 19:47:47.366553: Epoch 69\n",
      "2025-04-02 19:47:47.369233: Current learning rate: 0.00349\n",
      "train_loss -0.8329\n",
      "val_loss -0.8493\n",
      "Pseudo dice [0.8639]\n",
      "Epoch time: 152.69 s\n",
      "\n",
      "Epoch 70\n",
      "Current learning rate: 0.00338\n",
      "2025-04-02 19:48:01.481961: train_loss -0.8329\n",
      "2025-04-02 19:48:01.486084: val_loss -0.8493\n",
      "2025-04-02 19:48:01.488789: Pseudo dice [0.8639]\n",
      "2025-04-02 19:48:01.490870: Epoch time: 150.98 s\n",
      "2025-04-02 19:48:03.198267: \n",
      "2025-04-02 19:48:03.201743: Epoch 70\n",
      "2025-04-02 19:48:03.204211: Current learning rate: 0.00338\n",
      "train_loss -0.8374\n",
      "val_loss -0.8302\n",
      "Pseudo dice [0.8581]\n",
      "Epoch time: 152.63 s\n",
      "\n",
      "Epoch 69\n",
      "Current learning rate: 0.00349\n",
      "2025-04-02 19:49:22.450850: train_loss -0.8374\n",
      "2025-04-02 19:49:22.454085: val_loss -0.8302\n",
      "2025-04-02 19:49:22.455884: Pseudo dice [0.8581]\n",
      "2025-04-02 19:49:22.460883: Epoch time: 150.39 s\n",
      "2025-04-02 19:49:24.100159: \n",
      "2025-04-02 19:49:24.103125: Epoch 69\n",
      "2025-04-02 19:49:24.105600: Current learning rate: 0.00349\n",
      "train_loss -0.8193\n",
      "val_loss -0.8586\n",
      "Pseudo dice [0.8746]\n",
      "Epoch time: 152.76 s\n",
      "\n",
      "Epoch 70\n",
      "Current learning rate: 0.00338\n",
      "2025-04-02 19:50:18.400807: train_loss -0.8193\n",
      "2025-04-02 19:50:18.404938: val_loss -0.8586\n",
      "2025-04-02 19:50:18.407672: Pseudo dice [0.8746]\n",
      "2025-04-02 19:50:18.410420: Epoch time: 151.04 s\n",
      "2025-04-02 19:50:20.099763: \n",
      "2025-04-02 19:50:20.102657: Epoch 70\n",
      "2025-04-02 19:50:20.105199: Current learning rate: 0.00338\n",
      "train_loss -0.8323\n",
      "val_loss -0.852\n",
      "Pseudo dice [0.8729]\n",
      "Epoch time: 152.39 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8638\n",
      "2025-04-02 19:50:33.875886: train_loss -0.8323\n",
      "\n",
      "Epoch 71\n",
      "Current learning rate: 0.00328\n",
      "2025-04-02 19:50:33.878797: val_loss -0.852\n",
      "2025-04-02 19:50:33.880243: Pseudo dice [0.8729]\n",
      "2025-04-02 19:50:33.881819: Epoch time: 150.68 s\n",
      "2025-04-02 19:50:33.883833: Yayy! New best EMA pseudo Dice: 0.8638\n",
      "2025-04-02 19:50:36.059898: \n",
      "2025-04-02 19:50:36.062633: Epoch 71\n",
      "2025-04-02 19:50:36.065264: Current learning rate: 0.00328\n",
      "train_loss -0.8391\n",
      "val_loss -0.8344\n",
      "Pseudo dice [0.8611]\n",
      "Epoch time: 152.28 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8505\n",
      "\n",
      "Epoch 70\n",
      "Current learning rate: 0.00338\n",
      "2025-04-02 19:51:54.731547: train_loss -0.8391\n",
      "2025-04-02 19:51:54.736701: val_loss -0.8344\n",
      "2025-04-02 19:51:54.739155: Pseudo dice [0.8611]\n",
      "2025-04-02 19:51:54.741005: Epoch time: 150.63 s\n",
      "2025-04-02 19:51:54.743237: Yayy! New best EMA pseudo Dice: 0.8505\n",
      "2025-04-02 19:51:57.095503: \n",
      "2025-04-02 19:51:57.099893: Epoch 70\n",
      "2025-04-02 19:51:57.103184: Current learning rate: 0.00338\n",
      "train_loss -0.8195\n",
      "val_loss -0.8391\n",
      "Pseudo dice [0.8608]\n",
      "Epoch time: 152.86 s\n",
      "2025-04-02 19:52:51.263295: train_loss -0.8195\n",
      "2025-04-02 19:52:51.266167: val_loss -0.8391\n",
      "\n",
      "Epoch 71\n",
      "Current learning rate: 0.00328\n",
      "2025-04-02 19:52:51.268480: Pseudo dice [0.8608]\n",
      "2025-04-02 19:52:51.270888: Epoch time: 151.16 s\n",
      "2025-04-02 19:52:52.962290: \n",
      "2025-04-02 19:52:52.965840: Epoch 71\n",
      "2025-04-02 19:52:52.970277: Current learning rate: 0.00328\n",
      "train_loss -0.8366\n",
      "val_loss -0.8465\n",
      "Pseudo dice [0.8694]\n",
      "Epoch time: 152.85 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8644\n",
      "2025-04-02 19:53:06.729456: train_loss -0.8366\n",
      "\n",
      "Epoch 72\n",
      "Current learning rate: 0.00318\n",
      "2025-04-02 19:53:06.733089: val_loss -0.8465\n",
      "2025-04-02 19:53:06.735604: Pseudo dice [0.8694]\n",
      "2025-04-02 19:53:06.738470: Epoch time: 150.67 s\n",
      "2025-04-02 19:53:06.740983: Yayy! New best EMA pseudo Dice: 0.8644\n",
      "2025-04-02 19:53:09.040145: \n",
      "2025-04-02 19:53:09.042706: Epoch 72\n",
      "2025-04-02 19:53:09.044981: Current learning rate: 0.00318\n",
      "train_loss -0.8321\n",
      "val_loss -0.8222\n",
      "Pseudo dice [0.8443]\n",
      "Epoch time: 152.67 s\n",
      "\n",
      "Epoch 71\n",
      "Current learning rate: 0.00328\n",
      "2025-04-02 19:54:27.404754: train_loss -0.8321\n",
      "2025-04-02 19:54:27.407846: val_loss -0.8222\n",
      "2025-04-02 19:54:27.415043: Pseudo dice [0.8443]\n",
      "2025-04-02 19:54:27.419444: Epoch time: 150.31 s\n",
      "2025-04-02 19:54:29.013551: \n",
      "2025-04-02 19:54:29.016823: Epoch 71\n",
      "2025-04-02 19:54:29.019776: Current learning rate: 0.00328\n",
      "train_loss -0.8283\n",
      "val_loss -0.8552\n",
      "Pseudo dice [0.8729]\n",
      "Epoch time: 153.05 s\n",
      "2025-04-02 19:55:24.311546: train_loss -0.8283\n",
      "\n",
      "Epoch 72\n",
      "Current learning rate: 0.00318\n",
      "2025-04-02 19:55:24.313801: val_loss -0.8552\n",
      "2025-04-02 19:55:24.315638: Pseudo dice [0.8729]\n",
      "2025-04-02 19:55:24.317460: Epoch time: 151.35 s\n",
      "2025-04-02 19:55:25.989143: \n",
      "2025-04-02 19:55:25.997731: Epoch 72\n",
      "2025-04-02 19:55:26.001828: Current learning rate: 0.00318\n",
      "train_loss -0.8293\n",
      "val_loss -0.8384\n",
      "Pseudo dice [0.8564]\n",
      "Epoch time: 153.27 s\n",
      "\n",
      "Epoch 73\n",
      "Current learning rate: 0.00308\n",
      "2025-04-02 19:55:40.004512: train_loss -0.8293\n",
      "2025-04-02 19:55:40.008755: val_loss -0.8384\n",
      "2025-04-02 19:55:40.011432: Pseudo dice [0.8564]\n",
      "2025-04-02 19:55:40.013557: Epoch time: 150.97 s\n",
      "2025-04-02 19:55:41.666487: \n",
      "2025-04-02 19:55:41.669971: Epoch 73\n",
      "2025-04-02 19:55:41.673749: Current learning rate: 0.00308\n",
      "train_loss -0.8375\n",
      "val_loss -0.8251\n",
      "Pseudo dice [0.855]\n",
      "Epoch time: 151.9 s\n",
      "\n",
      "Epoch 72\n",
      "Current learning rate: 0.00318\n",
      "2025-04-02 19:56:59.303023: train_loss -0.8375\n",
      "2025-04-02 19:56:59.307301: val_loss -0.8251\n",
      "2025-04-02 19:56:59.309733: Pseudo dice [0.855]\n",
      "2025-04-02 19:56:59.312156: Epoch time: 150.29 s\n",
      "2025-04-02 19:57:00.969171: \n",
      "2025-04-02 19:57:00.971027: Epoch 72\n",
      "2025-04-02 19:57:00.972898: Current learning rate: 0.00318\n",
      "train_loss -0.8327\n",
      "val_loss -0.8502\n",
      "Pseudo dice [0.8692]\n",
      "Epoch time: 152.6 s\n",
      "2025-04-02 19:57:56.914901: train_loss -0.8327\n",
      "\n",
      "Epoch 73\n",
      "Current learning rate: 0.00308\n",
      "2025-04-02 19:57:56.917541: val_loss -0.8502\n",
      "2025-04-02 19:57:56.919006: Pseudo dice [0.8692]\n",
      "2025-04-02 19:57:56.920392: Epoch time: 150.93 s\n",
      "2025-04-02 19:57:58.831687: \n",
      "2025-04-02 19:57:58.834720: Epoch 73\n",
      "2025-04-02 19:57:58.837963: Current learning rate: 0.00308\n",
      "train_loss -0.8307\n",
      "val_loss -0.855\n",
      "Pseudo dice [0.8763]\n",
      "Epoch time: 152.62 s\n",
      "Yayy! New best EMA pseudo Dice: 0.8649\n",
      "2025-04-02 19:58:12.623644: train_loss -0.8307\n",
      "\n",
      "Epoch 74\n",
      "Current learning rate: 0.00297\n",
      "2025-04-02 19:58:12.627370: val_loss -0.855\n",
      "2025-04-02 19:58:12.629128: Pseudo dice [0.8763]\n",
      "2025-04-02 19:58:12.631176: Epoch time: 150.96 s\n",
      "2025-04-02 19:58:12.632976: Yayy! New best EMA pseudo Dice: 0.8649\n",
      "2025-04-02 19:58:15.041856: \n",
      "2025-04-02 19:58:15.044940: Epoch 74\n",
      "2025-04-02 19:58:15.047219: Current learning rate: 0.00297\n",
      "train_loss -0.832\n",
      "val_loss -0.824\n",
      "Pseudo dice [0.8463]\n",
      "Epoch time: 151.79 s\n",
      "2025-04-02 19:59:31.088185: train_loss -0.832\n",
      "2025-04-02 19:59:31.092449: val_loss -0.824\n",
      "\n",
      "Epoch 73\n",
      "Current learning rate: 0.00308\n",
      "2025-04-02 19:59:31.094615: Pseudo dice [0.8463]\n",
      "2025-04-02 19:59:31.096967: Epoch time: 150.12 s\n",
      "2025-04-02 19:59:32.752582: \n",
      "2025-04-02 19:59:32.755930: Epoch 73\n",
      "2025-04-02 19:59:32.759458: Current learning rate: 0.00308\n",
      "train_loss -0.8346\n",
      "val_loss -0.8572\n",
      "Pseudo dice [0.8718]\n",
      "Epoch time: 152.92 s\n",
      "\n",
      "2025-04-02 20:00:29.833756: train_loss -0.8346\n",
      "Epoch 74\n",
      "Current learning rate: 0.00297\n",
      "2025-04-02 20:00:29.836279: val_loss -0.8572\n",
      "2025-04-02 20:00:29.838001: Pseudo dice [0.8718]\n",
      "2025-04-02 20:00:29.839452: Epoch time: 151.0 s\n",
      "2025-04-02 20:00:31.516549: \n",
      "2025-04-02 20:00:31.520384: Epoch 74\n",
      "2025-04-02 20:00:31.522339: Current learning rate: 0.00297\n",
      "train_loss -0.8222\n",
      "val_loss -0.825\n",
      "Pseudo dice [0.856]\n",
      "Epoch time: 153.33 s\n",
      "2025-04-02 20:00:45.951530: train_loss -0.8222\n",
      "2025-04-02 20:00:45.953940: val_loss -0.825\n",
      "\n",
      "Epoch 75\n",
      "Current learning rate: 0.00287\n",
      "2025-04-02 20:00:45.955339: Pseudo dice [0.856]\n",
      "2025-04-02 20:00:45.956839: Epoch time: 150.91 s\n",
      "2025-04-02 20:00:47.518282: \n",
      "2025-04-02 20:00:47.520901: Epoch 75\n",
      "2025-04-02 20:00:47.522687: Current learning rate: 0.00287\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export nnUNet_raw=\"/home/jovyan/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/home/jovyan/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/jovyan/nnUNet_results\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=6 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_cascade_fullres 0 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=2,7 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_cascade_fullres 1 -num_gpus 2 & \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=1,2 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_cascade_fullres 2 -num_gpus 2 --c& \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=3,4 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_cascade_fullres 3 -num_gpus 2 --c& \n",
    "sleep 120\n",
    "CUDA_VISIBLE_DEVICES=5,6 .local/bin/nnUNetv2_train -device \"cuda\" 300 3d_cascade_fullres 4 -num_gpus 2 --c& \n",
    "sleep 120\n",
    "wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "There are 0 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 0 cases that I would like to predict\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export nnUNet_raw=\"/home/jovyan/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/home/jovyan/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/jovyan/nnUNet_results\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset400_supersecret/imagesTs -o /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/3d_fullres -d 300 -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans --save_probabilities\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=2 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset400_supersecret/imagesTs -o /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/3d_lowres -d 300 -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_lowres -p nnUNetPlans --save_probabilities\n",
    "# CUDA_VISIBLE_DEVICES=3 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset400_supersecret/imagesTs -o /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/2d -d 300 -f  0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans --save_probabilities\n",
    "wait\n",
    "# CUDA_VISIBLE_DEVICES=1 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset400_supersecret/imagesTs -o /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/3d_cascade_fullres -d 300 -f  0 1 2 3 4 -prev_stage_predictions /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/3d_lowres -tr nnUNetTrainer -c 3d_cascade_fullres -p nnUNetPlans --save_probabilities\n",
    "# wait\n",
    "# CUDA_VISIBLE_DEVICES=1 nnUNetv2_ensemble -i /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/3d_cascade_fullres /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/2d /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/3d_fullres /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/3d_lowres -o /home/jovyan/nnUNet_results/Dataset400_supersecret/inference/test/ensemble -np 36 --save_npz \n",
    "# wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export nnUNet_raw=\"/home/jovyan/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/home/jovyan/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/home/jovyan/nnUNet_results\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset300_combined/imagesTs -o /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/3d_fullres -d 300 -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans --save_probabilities\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset300_combined/imagesTs -o /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/3d_lowres -d 300 -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_lowres -p nnUNetPlans --save_probabilities\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset300_combined/imagesTs -o /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/2d -d 300 -f  0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans --save_probabilities\n",
    "wait\n",
    "# CUDA_VISIBLE_DEVICES=1 nnUNetv2_predict -i /home/jovyan/nnUNet_raw/Dataset300_combined/imagesTs -o /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/3d_cascade_fullres -d 300 -f  0 1 2 3 4 -prev_stage_predictions /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/3d_lowres -tr nnUNetTrainer -c 3d_cascade_fullres -p nnUNetPlans --save_probabilities\n",
    "# wait\n",
    "# CUDA_VISIBLE_DEVICES=1 nnUNetv2_ensemble -i /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/3d_cascade_fullres /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/2d /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/3d_fullres /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/3d_lowres -o /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/ensemble -np 36 --save_npz \n",
    "# wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n"
     ]
    }
   ],
   "source": [
    "nnUNetv2_evaluate_folder -djfile /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/ensemble/dataset.json \\\n",
    "                         -pfile /home/jovyan/nnUNet_results/Dataset300_combined/nnUNetTrainer__nnUNetPlans__3d_fullres/plans.json \\\n",
    "                         /home/jovyan/nnUNet_raw/Dataset300_combined/labelsTs \\\n",
    "                         /home/jovyan/nnUNet_results/Dataset300_combined/inference/test/ensemble\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
